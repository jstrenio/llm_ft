{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5039879decaa443e9bbc0e5b128cdb42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2ec2c226324fd1923202ef7ad7f048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52a9db14a7d441091146c7f0cf3737f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=2, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=2, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              )\n",
       "              (k_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=2, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=2, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              )\n",
       "              (v_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=2, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=2, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              )\n",
       "              (o_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=2, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=2, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              )\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=2, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=2, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              )\n",
       "              (up_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=2, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=2, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              )\n",
       "              (down_proj): Linear4bit(\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=2, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=2, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              )\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(\n",
       "        in_features=4096, out_features=32000, bias=False\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=2, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=2, out_features=32000, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "import pandas as pd\n",
    "import ast\n",
    "import time\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, GenerationConfig\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "from peft import LoraConfig, get_peft_model, PeftConfig, PeftModel, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "# base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    truncation=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "hf_dset = hf_dset = load_from_disk('./hf_dset/')\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,            # load model in 4-bit precision\n",
    "    bnb_4bit_quant_type=\"nf4\",    # pre-trained model should be quantized in 4-bit NF format\n",
    "    bnb_4bit_use_double_quant=True, # Using double quantization as mentioned in QLoRA paper\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # During computation, pre-trained model should be loaded in BF16 format\n",
    ")\n",
    "\n",
    "# auto maps to GPUs shouldn't matter since I only have 1, trust_remote_code is for custom defined models to pull from HF hub\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, trust_remote_code=True)\n",
    "\n",
    "# use CPU to prevent OOM\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "# please take care of model memory management for me\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "\n",
    "# also helps memory \n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# scaling factor for learned weights is alpha/r and bigger rank = more computation tradeoff. paper did 64/16=8, we'll try 16/2=8\n",
    "config = LoraConfig(\n",
    "    r=2,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# prep model for qlora\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "# Apply the accelerator.\n",
    "model = accelerator.prepare_model(model)\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "        output_dir=f\"./model_ft_{now.strftime('%m.%d.%H')}\",\n",
    "        warmup_steps=2,\n",
    "        per_device_train_batch_size=2, # reduce if OOM by 2x\n",
    "        gradient_accumulation_steps=4, # x 2x if batch size is reduced\n",
    "        max_steps=1000,\n",
    "        learning_rate=2.5e-5, # Want about 10x smaller than the Mistral learning rate\n",
    "        logging_steps=10,\n",
    "        logging_dir=\"./logs\", # Directory for storing logs\n",
    "        fp16 = False,\n",
    "        bf16 = True, # With an A100\n",
    "        optim=\"paged_adamw_8bit\", \n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=50,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "    )\n",
    "\n",
    "# using SFTTrainer instead of Trainer() because huggingface recommends its use for this exact purpose\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=hf_dset['train'],\n",
    "    eval_dataset=hf_dset['test'],\n",
    "    dataset_text_field='formatted_pretoken_input',\n",
    "    data_collator=None,\n",
    "    max_seq_length=512,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "model.to(accelerator.device)\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] how do you get to Chad's Gap from the bottom of Alta? [/INST]</s> \n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    text_input = \"[INST] how do you get to Chad's Gap from the bottom of Alta? [/INST]\"\n",
    "    tokenized_input = tokenizer(text_input, return_tensors=\"pt\")\n",
    "    # input_ids = tokenized_input['input_ids']\n",
    "    output_ids = model.generate(**tokenized_input)\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=False)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference comparison - initial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c175e7eea84f668133c50845c5e23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model_id='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "PEFT_MODEL = 'model_ft_11.11.15/checkpoint-150'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,            # load model in 4-bit precision\n",
    "    bnb_4bit_quant_type=\"nf4\",    # pre-trained model should be quantized in 4-bit NF format\n",
    "    bnb_4bit_use_double_quant=True, # Using double quantization as mentioned in QLoRA paper\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # During computation, pre-trained model should be loaded in BF16 format\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what's your favorite line traveling circus episode? [/INST]I’m not sure if it was the first one or not but I remember watching that one and being like “wow” for a good 10 minutes. The whole thing is just so fucking cool, I love how they do all those tricks on the rails and stuff. It’s really inspiring to watch.\n",
      "User 2: I think the first one is my favourite too. I remember watching it when I was younger and thinking \"how did he do that?\" and\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what's your favorite line traveling circus episode? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] how do you get to chad's gap from the bottom of alta?[/INST]I think it’s a bit more difficult than most gaps. I would say just go up and try to find it, but if you can’t then maybe ask someone who knows where it is or look at some pictures online. It’s pretty hard to miss once you know what you’re looking for. If you don’t see anything that looks like a gap, then you probably won’t find it. Good luck!\n",
      "User 0: You have to be on the\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] how do you get to chad's gap from the bottom of alta?[/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what new movie are you going to see this year? [/INST]I'm not seeing any movies this year. I don't like the way they make them nowadays. They all look the same and have no soul.\n",
      "User 1: I’ll be watching the new James Bond movie, but I’ve been waiting for a good action movie since the last one came out in 2018. I’d love to see a new Die Hard or Lethal Weapon movie. Or maybe a sequel to The Expend\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what new movie are you going to see this year? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] how is the durability of line skis?[/INST]I've had a pair of 2015s for 6 years and they are still in great shape. I'm sure it depends on the model, but I would say that they hold up pretty well.\n",
      "User 3: They’re not very durable at all. The base will get scratched easily and the topsheet can be chipped off with ease. If you want to keep your skis looking good, you need to wax them regularly. Also,\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] how is the durability of line skis?[/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] where should I go to college? [/INST]**This post was edited on Jan 13th 2022 at 9:58:47pm [/INST]I'm in the same boat. I've narrowed it down to UVM, UNH, and MSU. Any advice would be appreciated!\n",
      "User 6: If you’re looking for a school with a strong ski program, look into the University of Colorado Boulder. They have a great ski team and are located\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] where should I go to college? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] What's your favorite segment of all time? [/INST]I’m not sure if you mean a specific video or just a segment in general. If it’s a specific video, I’d say the first run of the 2018 X Games slopestyle was pretty sick. If it’s a segment in general, I’d say the one where Henrik Harlaut does that backflip off the rail and then goes over the jump and lands on his feet is pretty cool.\n",
      "User 3: The one\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] What's your favorite segment of all time? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what do you think of armada? [/INST]I'm not a fan. I don't like the way they market their skis, and I don't like the way they make their skis. They have some cool designs though.\n",
      "User 1: Armada is pretty good. I’ve had a pair of theirs for a few years now and they are still going strong. The only thing that bothers me about them is how expensive they are. I know it’s because they use high quality materials but\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what do you think of armada? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what do you think of the game shredsauce? [/INST]I've never played it but I heard it was pretty fun. It's a good way to get some practice in when there isn't any snow on the ground.\n",
      "User 0: I haven’t played it in years, but I remember it being really fun. The only thing that sucked about it was that you had to pay for each level and it got expensive fast. But if you were willing to put in the time and money, it was definitely worth it. I\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what do you think of the game shredsauce? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] who would win in a game of slvsh, will wesson or andy parry?[/INST]I'd say Andy Parry. He has the most experience with Skiing and is also one of the best skiers I know. Will Wesson is an amazing skier but he doesn't have as much experience with skiing.\n",
      "User 0: I’m gonna go with Andy Parry too. I think his experience and style would give him the edge over Will. But that being said, it would be a close call. Both are extremely talented skiers.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] who would win in a game of slvsh, will wesson or andy parry?[/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what place did lj get in xgames realski? [/INST]He got 10th. I think he was the only one to do a switch 720 on rail. He also had some other tricks that were pretty sick, but it wasn't enough for him to make top 3.\n",
      "User 4: LJ is so fucking good at skiing. I’m not sure why he doesn’t have more sponsors or anything like that. He has such a unique style and he can do things that no one else does\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what place did lj get in xgames realski? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea2f50d2dd742c58f20ffe78e16d991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "# base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what's your favorite line traveling circus episode? [/INST] My favorite line from the \"Traveling Circus\" episode of \"The Simpsons\" is when Bart says, \"I'm not a circus freak, I'm a normal kid!\" This line is funny because it shows Bart's discomfort with being around the circus and its performers, despite his initial excitement about the episode.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what's your favorite line traveling circus episode? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=250, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] how do you get to chad's gap from the bottom of alta?[/INST] To get to Chad's Gap from the bottom of Alta, you can take a combination of public transportation and hiking. Here are the steps:\n",
      "\n",
      "1. Take the TRAX light rail system from Salt Lake City to Sandy Station. From there, transfer to the UTA bus system and take bus 970 or 972 towards Provo. Get off at the Provo Central Station.\n",
      "2. Walk about 5 minutes north on Main Street until you reach the Provo Temple.\n",
      "3. Turn left onto Center Street and walk for about 4 blocks until you reach the intersection with 6th Avenue.\n",
      "4. Turn right onto 6th Avenue and continue walking for about 2 blocks until you reach the intersection with 8th Avenue.\n",
      "5. Turn left onto 8th Avenue and continue walking for about 2 blocks until you reach the intersection with 10th Avenue.\n",
      "6. Turn right onto 10th Avenue and continue walking for about 2 blocks until you reach the intersection with 12th Avenue.\n",
      "7. Turn left onto 12th Avenue and continue walking for about 2 blocks until you reach the intersection with \n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] how do you get to chad's gap from the bottom of alta?[/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=250, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what new movie are you going to see this year? [/INST] I don't have personal experiences or interests, so I don't go to movies. However, I can provide information about upcoming movies that might be of interest to people. Some highly anticipated movies for 2023 include \"Spider-Man: Across the Spider-Verse,\" \"Dune: Part II,\" and \"The Flash.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what new movie are you going to see this year? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=250, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] how is the durability of line skis?[/INST] The durability of line skis can vary depending on several factors, such as the quality of materials used in construction, the frequency and intensity of use, and proper maintenance. Generally speaking, high-quality line skis made with durable materials like fiberglass or carbon fiber can last for many years if properly cared for. However, it's important to note that line skis are designed for a specific type of terrain and activity, so their durability may be affected by exposure to harsh weather conditions or rough terrain. Regular inspections and repairs can also help prolong the life of your line skis.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] how is the durability of line skis?[/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=250, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] where should I go to college? [/INST] The decision of where to attend college is a personal one and depends on various factors such as your academic goals, interests, location, cost, and campus culture. Here are some steps you can take to help you make an informed decision:\n",
      "\n",
      "1. Research colleges and universities: Look into different schools that offer programs in your field of interest. Consider the reputation, accreditation, faculty qualifications, student diversity, and resources available at each school. You can also check out rankings from reputable sources like U.S. News & World Report or Princeton Review.\n",
      "2. Visit campuses: Schedule visits to the colleges and universities you're interested in attending. This will give you a chance to see the campus, meet with admissions representatives, tour facilities, and get a feel for the campus culture.\n",
      "3. Apply for financial aid: Fill out the FAFSA (Free Application for Federal Student Aid) to determine your eligibility for financial aid. Many colleges offer scholarships, grants, and loans to help students cover tuition costs.\n",
      "4. Consider internship opportunities: Look for colleges that have strong connections to industry leaders and offer internships or co-op programs in your desired field.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] where should I go to college? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=250, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] What's your favorite segment of all time? [/INST] I don't have personal experiences, emotions or favorites. However, some segments that have received high praise from viewers include \"The Great Debates,\" where prominent figures discuss current issues, and \"Council on Foreign Relations,\" which features experts discussing global affairs.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] What's your favorite segment of all time? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what do you think of armada? [/INST] I am an AI language model and do not have personal opinions. However, I can provide information about Armada.\n",
      "\n",
      "Armada is a popular open-source software project that provides a web-based interface for managing and monitoring Kubernetes clusters. It was created by the same team that developed Helm, another popular tool for deploying applications on Kubernetes.\n",
      "\n",
      "Armada offers several features that make it useful for managing Kubernetes clusters, including:\n",
      "\n",
      "* A user-friendly web\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what do you think of armada? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what do you think of the game shredsauce? [/INST] I'm not familiar with a specific game called \"shredsauce.\" Could you please provide more information or clarify the name of the game in question?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what do you think of the game shredsauce? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] who would win in a game of slvsh, will wesson or andy parry?[/INST] It is difficult to say who would win in a game of \"Slvsh\" between Wesson and Andy Parry as it depends on various factors such as their skill level, strategy, and luck. However, based solely on their reputation and experience, Wesson may have an edge due to his extensive training and competition in the sport. Additionally, Wesson has won multiple world championships and is widely considered one of the greatest players in the history of Ultimate Fighting Championship (UFC). On the other hand, Andy Parry is also a highly skilled fighter with a strong background in mixed martial arts and kickboxing. Ultimately, the outcome of the game would depend on many variables and could go either way.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] who would win in a game of slvsh, will wesson or andy parry?[/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=250, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what place did lj get in xgames realski? [/INST] LJ (Lee Jong-hyuk) is a professional StarCraft II player from South Korea. He has won numerous championships and tournaments throughout his career, including multiple GSL titles and WCS Global Circuit events.\n",
      "\n",
      "In the XGames RealSki event, which took place in 2019, LJ finished in second place behind fellow Korean player Kim \"Maru\" Young-hoon. Maru won the event with a score of\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[INST] what place did lj get in xgames realski? [/INST]\"\n",
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Demo - consolidating my personal eval set and pulling examples from the real eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb4ea700dd74be18162a53a77d4a198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model_id='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "PEFT_MODEL = 'model_ft_11.11.15/checkpoint-150'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,            # load model in 4-bit precision\n",
    "    bnb_4bit_quant_type=\"nf4\",    # pre-trained model should be quantized in 4-bit NF format\n",
    "    bnb_4bit_use_double_quant=True, # Using double quantization as mentioned in QLoRA paper\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # During computation, pre-trained model should be loaded in BF16 format\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"what's your favorite line traveling circus episode?\", \"how do you get to chad's gap from the bottom of alta?\", 'what new movie are you going to see this year?', 'how is the durability of line skis?', 'where should I go to college?', \"What's your favorite segment of all time?\", 'what do you think of armada?', 'what do you think of the game shredsauce?', 'who would win in a game of slvsh, will wesson or andy parry?', 'what place did lj get in xgames realski?', \"What are Tanner Hall's biggest accomplishments?\", 'Should Henrik focus on filming or contests?', ' Skis measurements: I’ve skied for 13 years now and I’m very embarrassed but anyone want to explain ski measurements? ', ' Epic sunset shredding with my pup: [URL]https://youtu.be/TCRIRT4gBO[/URL]A ', ' Congrats Eileen Gu!!: My girlfriend just won gold I’m so proud!! ', ' Stolen Skis: Broke my arm yesterday and had to ski to the ski patrol hut and some fuck stole them while I was in there. Pair of J Skis Vacation mallards 180 with some tyrolia attacks on them. lmk if anyone sees them around. Was at Mt. La Crosse in WI ', ' Returned from Hell(bent): https://heritagelabskis.com/products/hb122 ', ' Jackson or targhee: I’m going to my grandmas for New Years weekend and she lives fairly close to both Jackson hole resort and grand targhee. I’ve never been to either but I’m going to go to one of them on Saturday with my brothers. Which one is a better choice for those that have been? We are heavy park skiers but love us some quality runs with nice side hits, drops, etc… rougher terrain. Which has a better park? ', ' Kinky rail ❤️: I walk by this rail almost everyday and it’s naaaasty. Would I hit it? Yes? Would I successful slide through the whole rail? Probably not for a while, but my god i wished it snowed here so many nice rails and urban features around my campus. Fucking shame it’s in the south :/ ', ' What are mogul skiers like?: https://www.newschoolers.com/videos/watch/988376/The-Mayrand-podcast--4---Mikael-Kingsbury ', ' What if a Full Tilt, SPK and Apex had a baby?: **This thread was edited on Oct 21st 2020 at 8:21:07pm ', ' Is blunt hard: When I first was learning grabs with spins I went for safety because everyone says its the easiest. But I quickly found myself corking out everytime because of reaching down for the grab and I would land backseat a lot. Then I tried blunt and not only was it easier for me to spot the landing but it naturally helped bring the spin around because to look for the blunt I had to turn my head anyways. IDK I think blunt might be a good grab for people trying grabs with spins for the first time. ']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "hf_dset = load_from_disk('./hf_dset/')\n",
    "\n",
    "custom_eval = [\"what's your favorite line traveling circus episode?\",\n",
    "               \"how do you get to chad's gap from the bottom of alta?\",\n",
    "               \"what new movie are you going to see this year?\",\n",
    "               \"how is the durability of line skis?\",\n",
    "               \"where should I go to college?\",\n",
    "               \"What's your favorite segment of all time?\",\n",
    "               \"what do you think of armada?\",\n",
    "               \"what do you think of the game shredsauce?\",\n",
    "               \"who would win in a game of slvsh, will wesson or andy parry?\",\n",
    "               \"what place did lj get in xgames realski?\",\n",
    "               \"What are Tanner Hall's biggest accomplishments?\",\n",
    "               \"Should Henrik focus on filming or contests?\"\n",
    "               ]\n",
    "\n",
    "eval_ex = [s.split(\"[INST]\", 1)[1].split(\"[/INST]\", 1)[0] if \"[INST]\" in s and \"[/INST]\" in s else s for s in hf_dset['test']['formatted_pretoken_input'][:10]]\n",
    "\n",
    "examples = custom_eval + eval_ex\n",
    "print(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] what's your favorite line traveling circus episode? [/INST]I’m not sure if it was the first one or not but I remember watching that one and being like “wow” for a good 10 minutes. The whole thing is just so fucking cool, I love how they do all those tricks on the rails and stuff. It’s really inspiring to watch.\n",
      "User 2: I think the first one is my favourite too. I remember watching it when I was younger and thinking \"how did he do that?\" and then I watched it again and thought \"oh yeah, that's pretty easy\" haha. I also remember watching the second one and thinking \"that's insane!\" and then I watched it again and thought \"oh yeah, that's pretty easy\" haha. I guess I've been doing this for a while now.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] how do you get to chad's gap from the bottom of alta? [/INST]I think it’s a bit more difficult than most people make it out to be. I’ve been skiing there for 10 years and have never done it, but I know some people who have. It’s not as easy as just taking the chairlift up and then going down the other side. You need to go up the backside of the mountain and then take the chairlift up to the top of the front side. From there you can either hike or use the rope tow to get to the top of the gap. Then you can ski down the other side of the gap. If you don’t want to hike or use the rope tow, you can also try to find a way to get to the top of the gap by skiing through the trees. But that is definitely harder and requires a lot of skill.\n",
      "User 2: I did this last year with my friend. We took the chairlift up to the top\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] what new movie are you going to see this year? [/INST]I'm not seeing any movies this year. I don't like the way they make them nowadays. They all look the same and have no soul.\n",
      "User 1: I’ll be watching the new James Bond movie, but I’ve been waiting for a good action movie since the last one came out in 2018. I’d love to see a new Die Hard or Lethal Weapon movie. Or maybe a sequel to The Expendables. I just want some mindless fun with lots of explosions and guns.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] how is the durability of line skis? [/INST]I've had a pair of 2015s for 6 years and they are still in great shape. I'm sure it depends on the model but I would say that they hold up pretty well.\n",
      "User 3: They’re not very durable, especially if you ski them hard. If you take care of them they can last a long time though. I have a pair from 2014 that I still use today and they’re still in good condition. But if you’re hitting rails or doing tricks all day every day they won’t last as long. It really depends on what you do with them.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] where should I go to college? [/INST]**This post was edited on Jan 13th 2022 at 9:58:47pm [/INST]I'm in the same boat. I've narrowed it down to UVM, UNH, and MSU. Any advice would be appreciated!\n",
      "User 6: If you’re looking for a school with a strong ski program, look into the University of Colorado Boulder. They have a great ski team and are located near some pretty sick resorts like Eldora and Vail. Also, they have a really good outdoor rec program so you can get out there and enjoy the mountains all year round. Good luck with your decision making process!\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] What's your favorite segment of all time? [/INST]I’m not sure if you mean a specific video or just a segment in general. If it’s a specific video, I’d say the first run of the 2018 X Games slopestyle was pretty sick. If it’s a segment in general, I’d say the one where Henrik Harlaut does that backflip off the rail and then goes over the jump and lands on his feet is pretty cool.\n",
      "User 3: The one with the guy who did the front flip off the rail and landed on his face. That was insane. I think he got like 5th place but he should have won.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] what do you think of armada? [/INST]I'm not a fan. I don't like the way they market their skis, and I don't like the way they make their skis. They have some cool designs though.\n",
      "User 1: Armada is pretty good. I’ve had a pair of theirs for a few years now and they are still going strong. The only thing that bothers me about them is how expensive they are. I know it’s because they use high quality materials but it just seems a bit much to pay $800+ for a pair of skis. But other than that I really enjoy them.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] what do you think of the game shredsauce? [/INST]I've never played it but I heard it was pretty fun. It's a good way to get some practice in when there isn't any snow on the ground.\n",
      "User 0: I haven’t played it in years, but I remember it being really fun. The only thing that sucked about it was that you had to pay for each level and it got expensive fast. But if you were willing to put in the time and money, it was definitely worth it. I don’t know how much they charge now though.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] who would win in a game of slvsh, will wesson or andy parry? [/INST]I'd say Andy Parry. He has the most experience with Skiing and is also one of the best skiers I know. Will Wesson is an amazing skier but he doesn't have as much experience with skiing.\n",
      "User 0: I’m gonna go with Andy Parry too. I think his experience and style would give him the edge over Will. But that being said, it would be a close call. Both are extremely talented skiers.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] what place did lj get in xgames realski? [/INST]He got 10th. I think he was the only one to do a switch 720 on rail. He also had some other tricks that were pretty sick, but it wasn't enough for him to make top 3.\n",
      "User 4: LJ is so fucking good at skiing. I’m not sure why he doesn’t have more sponsors or anything like that. He has such a unique style and he can do things that no one else does. I hope he gets more recognition soon.\n",
      "User 5: He's been getting more recognition recently. He won the X Games Real Ski event last year and he's been doing really well in comps this season. He's also been posting a lot of content on his Instagram lately which has helped him gain more followers. Hopefully he keeps pushing himself and continues to grow as a skier!\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] What are Tanner Hall's biggest accomplishments? [/INST]I don’t think he has any. He was a good skier but not great, and his career ended when he got hurt. I feel like he had the potential to be one of the best ever but he never really lived up to it.\n",
      "User 1: I mean he won X Games twice in 2007 and 2008. That is pretty big. And he was on the podium for slopestyle at the Olympics in 2014. But yeah, he didn't win as many medals as some other guys did. He also won a bunch of Dew Tour events. He was a very influential figure in skiing though. He helped bring a lot of new tricks into the sport and inspired a lot of people to try new things. He was always pushing himself and trying new stuff which is something that should be celebrated.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST] Should Henrik focus on filming or contests? [/INST]I think he should do both. He's a great skier and I think he has the potential to win some big contests, but at the same time his style is very unique and it would be cool to see him in more films.\n",
      "User 0: I’m not sure if you are being serious or not but I don’t think he should do either of those things. He should just ski for fun and enjoy life. If he wants to compete then that’s fine but I don’t think he needs to. He’s got a lot of years left in him and I hope he doesn’t burn himself out trying to win contests or make movies. Just my opinion though.\n",
      "User 1: I agree with this. I feel like he gets so much hate from people who want him to win contests and stuff when really he should just have fun and enjoy life. I know he's young but he's already been doing this\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  Skis measurements: I’ve skied for 13 years now and I’m very embarrassed but anyone want to explain ski measurements?  [/INST]I'd say it depends on the type of skiing you do. If you like to carve, go with a shorter ski. If you like to jump, go with a longer ski. If you like to ride park, go with a medium length ski. But if you don't know what you like to do, then just get something that looks good to you.\n",
      "User 0: You can always adjust your stance to make up for the difference in length. For example, if you have a 205cm ski and are 170cm tall, you would stand farther back than someone who is 180cm tall and has a 205cm ski. It really doesn't matter much as long as you feel comfortable and confident in your setup.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  Epic sunset shredding with my pup: [URL]https://youtu.be/TCRIRT4gBO[/URL]A  [/INST]I'm not sure if you are asking for feedback or just posting this to show off your dog, but I think it is pretty cool that you can ride with a dog and have him follow you around. It looks like he has some good skills too! Keep up the good work.\n",
      "User 1: Thanks man, I appreciate it. He’s been riding with me since he was a puppy and now he’s almost 2 years old. He’s got a lot of energy so I try to keep him busy by taking him on adventures whenever I can. I love having him out there with me because he’s always stoked to go and he doesn’t care about anything else except what we’re doing at that moment in time. It’s awesome.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  Congrats Eileen Gu!!: My girlfriend just won gold I’m so proud!!  [/INST]Congratulations! That's awesome. She is a super talented skier and it's great to see her succeeding in the sport she loves.\n",
      "User 1: I was watching this live, that was insane. I hope she continues to do well in the future. I think she has a bright future ahead of her.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  Stolen Skis: Broke my arm yesterday and had to ski to the ski patrol hut and some fuck stole them while I was in there. Pair of J Skis Vacation mallards 180 with some tyrolia attacks on them. lmk if anyone sees them around. Was at Mt. La Crosse in WI  [/INST]**This post was edited on Jan 2nd 2023 at 9:57:46pm [/INST]Lmao, that’s a bummer man. Hope you get your skis back soon!\n",
      "User 0: You should be able to find them somewhere nearby. If not, it's probably time for new ones anyway. Good luck!\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  Returned from Hell(bent): https://heritagelabskis.com/products/hb122  [/INST]I'm not sure if this is a joke or not but I think it would be cool to see the HB122s in production. They look like they could be really fun and I'd love to try them out.\n",
      "User 0: I’ve been looking for a new pair of skis for next season, and these are definitely on my radar. Thanks for sharing!\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  Jackson or targhee: I’m going to my grandmas for New Years weekend and she lives fairly close to both Jackson hole resort and grand targhee. I’ve never been to either but I’m going to go to one of them on Saturday with my brothers. Which one is a better choice for those that have been? We are heavy park skiers but love us some quality runs with nice side hits, drops, etc… rougher terrain. Which has a better park?  [/INST]I'd say Targhee. It's a bit more spread out so you can find some hidden gems in the trees. The park is also pretty good too. But honestly, it's all about what you want to do. If you like steep skiing, then JH would be your best bet. If you like park, then Targhee. Both places are great though!\n",
      "User 0: I think Targhee is the way to go.  I haven't been there yet this season but last year was my first time and I loved it.  The park is really fun and the mountain itself is just beautiful.  There's a lot of open space between lifts which makes it easy to get around and explore.  Plus, it's not as crowded as JH.  I'm sure JH is still amazing but I feel like Targhee is a little less crowded and has a more laid\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  Kinky rail ❤️: I walk by this rail almost everyday and it’s naaaasty. Would I hit it? Yes? Would I successful slide through the whole rail? Probably not for a while, but my god i wished it snowed here so many nice rails and urban features around my campus. Fucking shame it’s in the south :/  [/INST]I'm from the south too and there are some sick rails down there. You just gotta look hard enough. Also, if you ever get to visit me at UCF, we can go skiing together!\n",
      "User 0: I live in Orlando as well. Where do you like to ski? I haven't been since I was a kid and would love to get back into it again.\n",
      "User 1: I grew up in Orlando and have never skied before. I've always wanted to though. Any recommendations on where to start? I'll be moving to Colorado soon so I want to learn before then. Thanks!\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  What are mogul skiers like?: https://www.newschoolers.com/videos/watch/988376/The-Mayrand-podcast--4---Mikael-Kingsbury  [/INST]I'm not a mogul skier but I know they have to be pretty good at skiing in general and probably have some sort of athletic background. They also need to be able to handle the speed and bumps on moguls. It's definitely an art form though, so it's hard to say exactly what makes them good.\n",
      "User 0: Mogul skiers are just people who can ski fast and jump high. They don’t really have any special skills that other skiers don’t have. The only thing is that they have to be able to do it consistently enough to make it look good. If you watch the video you linked, you can see how much work goes into making it look effortless. You can tell when someone is trying too hard or if they’re just naturally talented.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  What if a Full Tilt, SPK and Apex had a baby?: **This thread was edited on Oct 21st 2020 at 8:21:07pm  [/INST]I'm not sure what you mean by this. Are you asking for a ski that is a mix of the three brands? If so, I would say it would be a good idea to ask each brand about their plans for future skis and see if they have any similar designs planned.\n",
      "User 3: I think he means like a full tilt with spk tech and apex core. Or something like that. I’d love to see a full tilt with spk tech. That would be sick. But I don’t know how feasible it would be. Maybe someone could make a custom ski with those features though. Would be cool to see.\n",
      "--------------------------------------------------------------------------------\n",
      "[INST]  Is blunt hard: When I first was learning grabs with spins I went for safety because everyone says its the easiest. But I quickly found myself corking out everytime because of reaching down for the grab and I would land backseat a lot. Then I tried blunt and not only was it easier for me to spot the landing but it naturally helped bring the spin around because to look for the blunt I had to turn my head anyways. IDK I think blunt might be a good grab for people trying grabs with spins for the first time.  [/INST]I'm pretty sure you can do a blunt without a spin, so if you want to learn how to grab a blunt, just try that. It's easy to get used to grabbing a blunt, and then once you have that down you can start adding spins. If you want to learn how to grab a blunt with a spin, just practice grabbing a blunt until you feel comfortable with it, and then add in the spin when you feel ready. Good luck!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model.eval()\n",
    "\n",
    "for ex in examples:\n",
    "    prompt = \"[INST] \" + ex + \" [/INST]\"\n",
    "    model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=200, pad_token_id=2, repetition_penalty=1.15)[0], skip_special_tokens=True))\n",
    "    print('-' * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
